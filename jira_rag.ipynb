{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 0 - Setup environmental variables; should be moved to separate place\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "email = os.getenv(\"EMAIL\")\n",
    "api_token = os.getenv(\"JIRA_API_TOKEN\")\n",
    "server_url = os.getenv(\"SERVER_URL\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Use the variables in your code\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "import openai\n",
    "openai.api_key = openai_api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Customize llama_index Jira Reader as original one is not capable of reading in metadata with Dict or List\n",
    "\n",
    "from llama_index.readers.jira import JiraReader\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "\n",
    "class MyJiraReader(JiraReader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.verbose = False\n",
    "\n",
    "    def set_verbose(self, verbose):\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def load_data(self, query: str, start_at: int = 0, max_results: int = 50):\n",
    "        issues = super().load_data(query, start_at, max_results)\n",
    "\n",
    "        issues_with_clean_metadata = []\n",
    "        for issue in issues:\n",
    "            # Get the full Jira issue\n",
    "            jira_issue = self.jira.issue(issue.doc_id)\n",
    "            print(f\"Jira ticket ID: {issue.doc_id} - URL: {issue.extra_info.get('url', 'N/A')}\")\n",
    "            \n",
    "            # Fetch the comments (Move comments out of metadata)\n",
    "            comments = jira_issue.fields.comment.comments\n",
    "            comments_text = [comment.body for comment in comments]\n",
    "            comments_str = \"\\n\".join(comments_text)  # Join comments into a single string\n",
    "\n",
    "            # Get all metadata dynamically from the issue's extra_info\n",
    "            extra_info = issue.extra_info\n",
    "\n",
    "            # Ensure that all metadata values conform to valid types\n",
    "            extra_info = self.ensure_metadata_compliance(extra_info)\n",
    "\n",
    "            # Move comments into the main content (not metadata)\n",
    "            main_text_with_comments = issue.text + \"\\nComments:\\n\" + comments_str\n",
    "\n",
    "            # Append the updated issue with comments and compliant metadata to the list\n",
    "            issues_with_clean_metadata.append(\n",
    "                Document(\n",
    "                    text=main_text_with_comments,  # Include comments in the main text\n",
    "                    doc_id=issue.doc_id,\n",
    "                    extra_info=extra_info  # Metadata without comments\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Now, apply transformations and log metadata\n",
    "        nodes = run_transformations(\n",
    "            issues_with_clean_metadata,\n",
    "            transformations=[],  # Provide an empty list if no transformations are required\n",
    "            show_progress=True  # Optionally show progress\n",
    "        )\n",
    "\n",
    "        # Log metadata sizes by type and total size after transformations, controlled by verbose flag\n",
    "        for node in nodes:\n",
    "            total_size, metadata_size, metadata_breakdown, main_text_size = self.calculate_metadata_size_by_type(node)\n",
    "            print(f\"Transformed node ID: {node.doc_id}, total size: {total_size}, metadata size: {metadata_size}, main text size: {main_text_size}\")\n",
    "            # <-- Only print logs if verbose is True\n",
    "            if self.verbose:  \n",
    "                print(f\"Metadata breakdown for node {node.doc_id}:\")\n",
    "                for field, size in metadata_breakdown.items():\n",
    "                    print(f\"  - {field}: {size} characters\")\n",
    "\n",
    "            # Check if the metadata size exceeds the chunk size\n",
    "            if metadata_size > 1024:\n",
    "                print(f\"Node with ID: {node.doc_id} exceeds chunk size after transformation. Metadata size: {metadata_size}\")\n",
    "                if self.verbose:\n",
    "                    print(f\"Full metadata for node {node.doc_id}: {node.extra_info}\")\n",
    "\n",
    "        return nodes\n",
    "    \n",
    "    def ensure_metadata_compliance(self, metadata):\n",
    "        \"\"\"Ensure that all metadata values are of valid types.\"\"\"\n",
    "        if isinstance(metadata, dict):\n",
    "            for key, value in metadata.items():\n",
    "                # If the value is a list, convert it to a comma-separated string\n",
    "                if isinstance(value, list):\n",
    "                    metadata[key] = ', '.join(map(str, value))\n",
    "                # If the value is a dictionary, convert it to a string (or JSON string if needed)\n",
    "                elif isinstance(value, dict):\n",
    "                    metadata[key] = str(value)  # Or use json.dumps(value) for JSON format\n",
    "                # For all other types, leave it as is if it's str, int, float, or None\n",
    "                elif not isinstance(value, (str, int, float, type(None))):\n",
    "                    metadata[key] = str(value)  # Convert unsupported types to string\n",
    "        return metadata\n",
    "    \n",
    "    def calculate_metadata_size_by_type(self, node):\n",
    "        \"\"\"Calculate both the total size of the document and the size of each metadata field.\"\"\"\n",
    "        text_length = len(node.text) if node.text else 0  # Length of the main text\n",
    "        metadata_size = 0\n",
    "        metadata_breakdown = {}\n",
    "\n",
    "        # Calculate the size of each metadata field\n",
    "        if node.extra_info:\n",
    "            for key, value in node.extra_info.items():\n",
    "                field_size = len(str(value)) if value else 0\n",
    "                metadata_size += field_size\n",
    "                metadata_breakdown[key] = field_size\n",
    "\n",
    "        # Calculate the total size (text + metadata)\n",
    "        total_size = text_length + metadata_size\n",
    "\n",
    "        return total_size, metadata_size, metadata_breakdown, text_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Connect to Jira system, and read Jira tickets \n",
    "reader = MyJiraReader(\n",
    "    email=email, api_token=api_token, server_url=server_url\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bing/Projects/18_jirarag/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jira ticket ID: 328390 - URL: https://cybereason.atlassian.net/browse/DFND-70632\n",
      "Jira ticket ID: 328327 - URL: https://cybereason.atlassian.net/browse/DFND-70617\n",
      "Jira ticket ID: 328109 - URL: https://cybereason.atlassian.net/browse/DFND-70567\n",
      "Jira ticket ID: 328104 - URL: https://cybereason.atlassian.net/browse/DFND-70566\n",
      "Jira ticket ID: 328077 - URL: https://cybereason.atlassian.net/browse/DFND-70553\n",
      "Jira ticket ID: 328045 - URL: https://cybereason.atlassian.net/browse/DFND-70549\n",
      "Jira ticket ID: 328016 - URL: https://cybereason.atlassian.net/browse/DFND-70537\n",
      "Jira ticket ID: 327802 - URL: https://cybereason.atlassian.net/browse/DFND-70506\n",
      "Jira ticket ID: 327801 - URL: https://cybereason.atlassian.net/browse/DFND-70505\n",
      "Jira ticket ID: 327720 - URL: https://cybereason.atlassian.net/browse/DFND-70486\n",
      "Jira ticket ID: 327717 - URL: https://cybereason.atlassian.net/browse/DFND-70483\n",
      "Jira ticket ID: 327709 - URL: https://cybereason.atlassian.net/browse/DFND-70475\n",
      "Jira ticket ID: 326945 - URL: https://cybereason.atlassian.net/browse/DFND-70429\n",
      "Jira ticket ID: 326944 - URL: https://cybereason.atlassian.net/browse/DFND-70428\n",
      "Jira ticket ID: 326917 - URL: https://cybereason.atlassian.net/browse/DFND-70420\n",
      "Jira ticket ID: 326880 - URL: https://cybereason.atlassian.net/browse/DFND-70418\n",
      "Jira ticket ID: 326863 - URL: https://cybereason.atlassian.net/browse/DFND-70409\n",
      "Jira ticket ID: 326783 - URL: https://cybereason.atlassian.net/browse/DFND-70376\n",
      "Jira ticket ID: 326781 - URL: https://cybereason.atlassian.net/browse/DFND-70375\n",
      "Jira ticket ID: 326771 - URL: https://cybereason.atlassian.net/browse/DFND-70370\n",
      "Jira ticket ID: 326768 - URL: https://cybereason.atlassian.net/browse/DFND-70369\n",
      "Jira ticket ID: 326762 - URL: https://cybereason.atlassian.net/browse/DFND-70366\n",
      "Jira ticket ID: 326758 - URL: https://cybereason.atlassian.net/browse/DFND-70364\n",
      "Jira ticket ID: 326699 - URL: https://cybereason.atlassian.net/browse/DFND-70329\n",
      "Jira ticket ID: 326689 - URL: https://cybereason.atlassian.net/browse/DFND-70325\n",
      "Jira ticket ID: 326653 - URL: https://cybereason.atlassian.net/browse/DFND-70312\n",
      "Jira ticket ID: 326643 - URL: https://cybereason.atlassian.net/browse/DFND-70307\n",
      "Jira ticket ID: 326574 - URL: https://cybereason.atlassian.net/browse/DFND-70287\n",
      "Jira ticket ID: 326566 - URL: https://cybereason.atlassian.net/browse/DFND-70286\n",
      "Jira ticket ID: 326561 - URL: https://cybereason.atlassian.net/browse/DFND-70284\n",
      "Jira ticket ID: 326557 - URL: https://cybereason.atlassian.net/browse/DFND-70283\n",
      "Jira ticket ID: 326553 - URL: https://cybereason.atlassian.net/browse/DFND-70280\n",
      "Jira ticket ID: 326548 - URL: https://cybereason.atlassian.net/browse/DFND-70275\n",
      "Jira ticket ID: 326502 - URL: https://cybereason.atlassian.net/browse/DFND-70273\n",
      "Jira ticket ID: 326493 - URL: https://cybereason.atlassian.net/browse/DFND-70271\n",
      "Jira ticket ID: 326462 - URL: https://cybereason.atlassian.net/browse/DFND-70269\n",
      "Jira ticket ID: 326386 - URL: https://cybereason.atlassian.net/browse/DFND-70247\n",
      "Jira ticket ID: 326385 - URL: https://cybereason.atlassian.net/browse/DFND-70246\n",
      "Jira ticket ID: 326379 - URL: https://cybereason.atlassian.net/browse/DFND-70245\n",
      "Jira ticket ID: 326376 - URL: https://cybereason.atlassian.net/browse/DFND-70243\n",
      "Jira ticket ID: 326367 - URL: https://cybereason.atlassian.net/browse/DFND-70240\n",
      "Jira ticket ID: 326349 - URL: https://cybereason.atlassian.net/browse/DFND-70236\n",
      "Jira ticket ID: 326340 - URL: https://cybereason.atlassian.net/browse/DFND-70233\n",
      "Jira ticket ID: 326315 - URL: https://cybereason.atlassian.net/browse/DFND-70227\n",
      "Jira ticket ID: 326289 - URL: https://cybereason.atlassian.net/browse/DFND-70224\n",
      "Jira ticket ID: 326288 - URL: https://cybereason.atlassian.net/browse/DFND-70223\n",
      "Jira ticket ID: 326287 - URL: https://cybereason.atlassian.net/browse/DFND-70222\n",
      "Jira ticket ID: 326286 - URL: https://cybereason.atlassian.net/browse/DFND-70221\n",
      "Jira ticket ID: 326284 - URL: https://cybereason.atlassian.net/browse/DFND-70219\n",
      "Jira ticket ID: 326242 - URL: https://cybereason.atlassian.net/browse/DFND-70200\n",
      "Jira ticket ID: 326227 - URL: https://cybereason.atlassian.net/browse/DFND-70190\n",
      "Jira ticket ID: 326209 - URL: https://cybereason.atlassian.net/browse/DFND-70188\n",
      "Jira ticket ID: 326208 - URL: https://cybereason.atlassian.net/browse/DFND-70187\n",
      "Jira ticket ID: 326148 - URL: https://cybereason.atlassian.net/browse/DFND-70156\n",
      "Jira ticket ID: 326127 - URL: https://cybereason.atlassian.net/browse/DFND-70138\n",
      "Jira ticket ID: 326069 - URL: https://cybereason.atlassian.net/browse/DFND-70126\n",
      "Jira ticket ID: 326064 - URL: https://cybereason.atlassian.net/browse/DFND-70124\n",
      "Jira ticket ID: 325973 - URL: https://cybereason.atlassian.net/browse/DFND-70117\n",
      "Jira ticket ID: 325946 - URL: https://cybereason.atlassian.net/browse/DFND-70093\n",
      "Jira ticket ID: 325901 - URL: https://cybereason.atlassian.net/browse/DFND-70062\n",
      "Jira ticket ID: 325898 - URL: https://cybereason.atlassian.net/browse/DFND-70060\n",
      "Jira ticket ID: 325836 - URL: https://cybereason.atlassian.net/browse/DFND-70042\n",
      "Jira ticket ID: 325826 - URL: https://cybereason.atlassian.net/browse/DFND-70034\n",
      "Jira ticket ID: 325817 - URL: https://cybereason.atlassian.net/browse/DFND-70027\n",
      "Jira ticket ID: 325702 - URL: https://cybereason.atlassian.net/browse/DFND-69945\n",
      "Jira ticket ID: 325699 - URL: https://cybereason.atlassian.net/browse/DFND-69943\n",
      "Jira ticket ID: 325693 - URL: https://cybereason.atlassian.net/browse/DFND-69942\n",
      "Jira ticket ID: 325691 - URL: https://cybereason.atlassian.net/browse/DFND-69941\n",
      "Jira ticket ID: 325672 - URL: https://cybereason.atlassian.net/browse/DFND-69938\n",
      "Jira ticket ID: 325650 - URL: https://cybereason.atlassian.net/browse/DFND-69933\n",
      "Jira ticket ID: 325641 - URL: https://cybereason.atlassian.net/browse/DFND-69930\n",
      "Jira ticket ID: 325595 - URL: https://cybereason.atlassian.net/browse/DFND-69922\n",
      "Jira ticket ID: 325575 - URL: https://cybereason.atlassian.net/browse/DFND-69918\n",
      "Jira ticket ID: 325561 - URL: https://cybereason.atlassian.net/browse/DFND-69912\n",
      "Jira ticket ID: 325547 - URL: https://cybereason.atlassian.net/browse/DFND-69905\n",
      "Jira ticket ID: 325524 - URL: https://cybereason.atlassian.net/browse/DFND-69902\n",
      "Jira ticket ID: 325523 - URL: https://cybereason.atlassian.net/browse/DFND-69901\n",
      "Jira ticket ID: 325522 - URL: https://cybereason.atlassian.net/browse/DFND-69900\n",
      "Jira ticket ID: 325518 - URL: https://cybereason.atlassian.net/browse/DFND-69898\n",
      "Jira ticket ID: 325502 - URL: https://cybereason.atlassian.net/browse/DFND-69893\n",
      "Jira ticket ID: 325498 - URL: https://cybereason.atlassian.net/browse/DFND-69891\n",
      "Jira ticket ID: 325462 - URL: https://cybereason.atlassian.net/browse/DFND-69880\n",
      "Jira ticket ID: 325461 - URL: https://cybereason.atlassian.net/browse/DFND-69879\n",
      "Jira ticket ID: 325450 - URL: https://cybereason.atlassian.net/browse/DFND-69877\n",
      "Jira ticket ID: 325356 - URL: https://cybereason.atlassian.net/browse/DFND-69870\n",
      "Jira ticket ID: 325245 - URL: https://cybereason.atlassian.net/browse/DFND-69841\n",
      "Jira ticket ID: 325235 - URL: https://cybereason.atlassian.net/browse/DFND-69840\n",
      "Jira ticket ID: 325226 - URL: https://cybereason.atlassian.net/browse/DFND-69836\n",
      "Jira ticket ID: 325205 - URL: https://cybereason.atlassian.net/browse/DFND-69832\n",
      "Jira ticket ID: 325175 - URL: https://cybereason.atlassian.net/browse/DFND-69829\n",
      "Jira ticket ID: 325165 - URL: https://cybereason.atlassian.net/browse/DFND-69828\n",
      "Jira ticket ID: 325163 - URL: https://cybereason.atlassian.net/browse/DFND-69827\n",
      "Jira ticket ID: 325142 - URL: https://cybereason.atlassian.net/browse/DFND-69825\n",
      "Jira ticket ID: 325084 - URL: https://cybereason.atlassian.net/browse/DFND-69807\n",
      "Jira ticket ID: 325081 - URL: https://cybereason.atlassian.net/browse/DFND-69806\n",
      "Jira ticket ID: 324998 - URL: https://cybereason.atlassian.net/browse/DFND-69793\n",
      "Jira ticket ID: 324915 - URL: https://cybereason.atlassian.net/browse/DFND-69757\n",
      "Jira ticket ID: 324788 - URL: https://cybereason.atlassian.net/browse/DFND-69717\n",
      "Jira ticket ID: 324757 - URL: https://cybereason.atlassian.net/browse/DFND-69715\n",
      "Jira ticket ID: 324722 - URL: https://cybereason.atlassian.net/browse/DFND-69707\n",
      "Transformed node ID: 328390, total size: 593, metadata size: 188, main text size: 405\n",
      "Transformed node ID: 328327, total size: 5372, metadata size: 271, main text size: 5101\n",
      "Transformed node ID: 328109, total size: 1062, metadata size: 190, main text size: 872\n",
      "Transformed node ID: 328104, total size: 837, metadata size: 221, main text size: 616\n",
      "Transformed node ID: 328077, total size: 47268, metadata size: 190, main text size: 47078\n",
      "Transformed node ID: 328045, total size: 2045, metadata size: 218, main text size: 1827\n",
      "Transformed node ID: 328016, total size: 578, metadata size: 304, main text size: 274\n",
      "Transformed node ID: 327802, total size: 1761, metadata size: 348, main text size: 1413\n",
      "Transformed node ID: 327801, total size: 27424, metadata size: 320, main text size: 27104\n",
      "Transformed node ID: 327720, total size: 936, metadata size: 267, main text size: 669\n",
      "Transformed node ID: 327717, total size: 16428, metadata size: 272, main text size: 16156\n",
      "Transformed node ID: 327709, total size: 3455, metadata size: 334, main text size: 3121\n",
      "Transformed node ID: 326945, total size: 3589, metadata size: 298, main text size: 3291\n",
      "Transformed node ID: 326944, total size: 1098, metadata size: 240, main text size: 858\n",
      "Transformed node ID: 326917, total size: 52182, metadata size: 248, main text size: 51934\n",
      "Transformed node ID: 326880, total size: 1068, metadata size: 234, main text size: 834\n",
      "Transformed node ID: 326863, total size: 487, metadata size: 251, main text size: 236\n",
      "Transformed node ID: 326783, total size: 4421, metadata size: 246, main text size: 4175\n",
      "Transformed node ID: 326781, total size: 14946, metadata size: 311, main text size: 14635\n",
      "Transformed node ID: 326771, total size: 2322, metadata size: 294, main text size: 2028\n",
      "Transformed node ID: 326768, total size: 5953, metadata size: 277, main text size: 5676\n",
      "Transformed node ID: 326762, total size: 18473, metadata size: 310, main text size: 18163\n",
      "Transformed node ID: 326758, total size: 609, metadata size: 205, main text size: 404\n",
      "Transformed node ID: 326699, total size: 19643, metadata size: 287, main text size: 19356\n",
      "Transformed node ID: 326689, total size: 1802, metadata size: 276, main text size: 1526\n",
      "Transformed node ID: 326653, total size: 12958, metadata size: 383, main text size: 12575\n",
      "Transformed node ID: 326643, total size: 3962, metadata size: 340, main text size: 3622\n",
      "Transformed node ID: 326574, total size: 473, metadata size: 281, main text size: 192\n",
      "Transformed node ID: 326566, total size: 2332, metadata size: 283, main text size: 2049\n",
      "Transformed node ID: 326561, total size: 2642, metadata size: 302, main text size: 2340\n",
      "Transformed node ID: 326557, total size: 2412, metadata size: 301, main text size: 2111\n",
      "Transformed node ID: 326553, total size: 3520, metadata size: 319, main text size: 3201\n",
      "Transformed node ID: 326548, total size: 7352, metadata size: 326, main text size: 7026\n",
      "Transformed node ID: 326502, total size: 2514, metadata size: 283, main text size: 2231\n",
      "Transformed node ID: 326493, total size: 12509, metadata size: 341, main text size: 12168\n",
      "Transformed node ID: 326462, total size: 1753, metadata size: 317, main text size: 1436\n",
      "Transformed node ID: 326386, total size: 1081, metadata size: 349, main text size: 732\n",
      "Transformed node ID: 326385, total size: 2310, metadata size: 333, main text size: 1977\n",
      "Transformed node ID: 326379, total size: 896, metadata size: 304, main text size: 592\n",
      "Transformed node ID: 326376, total size: 1040, metadata size: 308, main text size: 732\n",
      "Transformed node ID: 326367, total size: 2827, metadata size: 340, main text size: 2487\n",
      "Transformed node ID: 326349, total size: 1307, metadata size: 293, main text size: 1014\n",
      "Transformed node ID: 326340, total size: 3175, metadata size: 297, main text size: 2878\n",
      "Transformed node ID: 326315, total size: 911, metadata size: 279, main text size: 632\n",
      "Transformed node ID: 326289, total size: 7128, metadata size: 306, main text size: 6822\n",
      "Transformed node ID: 326288, total size: 4339, metadata size: 356, main text size: 3983\n",
      "Transformed node ID: 326287, total size: 5237, metadata size: 347, main text size: 4890\n",
      "Transformed node ID: 326286, total size: 3042, metadata size: 329, main text size: 2713\n",
      "Transformed node ID: 326284, total size: 4007, metadata size: 327, main text size: 3680\n",
      "Transformed node ID: 326242, total size: 1084, metadata size: 282, main text size: 802\n",
      "Transformed node ID: 326227, total size: 5448, metadata size: 289, main text size: 5159\n",
      "Transformed node ID: 326209, total size: 1017, metadata size: 268, main text size: 749\n",
      "Transformed node ID: 326208, total size: 547, metadata size: 270, main text size: 277\n",
      "Transformed node ID: 326148, total size: 737, metadata size: 289, main text size: 448\n",
      "Transformed node ID: 326127, total size: 1611, metadata size: 296, main text size: 1315\n",
      "Transformed node ID: 326069, total size: 6904, metadata size: 327, main text size: 6577\n",
      "Transformed node ID: 326064, total size: 5076, metadata size: 343, main text size: 4733\n",
      "Transformed node ID: 325973, total size: 9374, metadata size: 408, main text size: 8966\n",
      "Transformed node ID: 325946, total size: 921, metadata size: 308, main text size: 613\n",
      "Transformed node ID: 325901, total size: 768, metadata size: 264, main text size: 504\n",
      "Transformed node ID: 325898, total size: 5038, metadata size: 288, main text size: 4750\n",
      "Transformed node ID: 325836, total size: 1096, metadata size: 297, main text size: 799\n",
      "Transformed node ID: 325826, total size: 4575, metadata size: 371, main text size: 4204\n",
      "Transformed node ID: 325817, total size: 5343, metadata size: 328, main text size: 5015\n",
      "Transformed node ID: 325702, total size: 554, metadata size: 302, main text size: 252\n",
      "Transformed node ID: 325699, total size: 965, metadata size: 272, main text size: 693\n",
      "Transformed node ID: 325693, total size: 6871, metadata size: 277, main text size: 6594\n",
      "Transformed node ID: 325691, total size: 3150, metadata size: 386, main text size: 2764\n",
      "Transformed node ID: 325672, total size: 28736, metadata size: 299, main text size: 28437\n",
      "Transformed node ID: 325650, total size: 1000, metadata size: 278, main text size: 722\n",
      "Transformed node ID: 325641, total size: 934, metadata size: 402, main text size: 532\n",
      "Transformed node ID: 325595, total size: 451, metadata size: 313, main text size: 138\n",
      "Transformed node ID: 325575, total size: 9969, metadata size: 350, main text size: 9619\n",
      "Transformed node ID: 325561, total size: 2453, metadata size: 317, main text size: 2136\n",
      "Transformed node ID: 325547, total size: 5649, metadata size: 318, main text size: 5331\n",
      "Transformed node ID: 325524, total size: 696, metadata size: 274, main text size: 422\n",
      "Transformed node ID: 325523, total size: 3207, metadata size: 291, main text size: 2916\n",
      "Transformed node ID: 325522, total size: 1523, metadata size: 348, main text size: 1175\n",
      "Transformed node ID: 325518, total size: 1761, metadata size: 253, main text size: 1508\n",
      "Transformed node ID: 325502, total size: 675, metadata size: 272, main text size: 403\n",
      "Transformed node ID: 325498, total size: 4707, metadata size: 269, main text size: 4438\n",
      "Transformed node ID: 325462, total size: 2702, metadata size: 293, main text size: 2409\n",
      "Transformed node ID: 325461, total size: 6580, metadata size: 326, main text size: 6254\n",
      "Transformed node ID: 325450, total size: 11560, metadata size: 341, main text size: 11219\n",
      "Transformed node ID: 325356, total size: 9339, metadata size: 329, main text size: 9010\n",
      "Transformed node ID: 325245, total size: 14099, metadata size: 294, main text size: 13805\n",
      "Transformed node ID: 325235, total size: 4421, metadata size: 349, main text size: 4072\n",
      "Transformed node ID: 325226, total size: 10771, metadata size: 284, main text size: 10487\n",
      "Transformed node ID: 325205, total size: 893, metadata size: 245, main text size: 648\n",
      "Transformed node ID: 325175, total size: 7614, metadata size: 295, main text size: 7319\n",
      "Transformed node ID: 325165, total size: 3168, metadata size: 307, main text size: 2861\n",
      "Transformed node ID: 325163, total size: 2633, metadata size: 287, main text size: 2346\n",
      "Transformed node ID: 325142, total size: 22537, metadata size: 322, main text size: 22215\n",
      "Transformed node ID: 325084, total size: 876, metadata size: 304, main text size: 572\n",
      "Transformed node ID: 325081, total size: 827, metadata size: 293, main text size: 534\n",
      "Transformed node ID: 324998, total size: 1962, metadata size: 308, main text size: 1654\n",
      "Transformed node ID: 324915, total size: 659, metadata size: 357, main text size: 302\n",
      "Transformed node ID: 324788, total size: 699, metadata size: 302, main text size: 397\n",
      "Transformed node ID: 324757, total size: 22334, metadata size: 316, main text size: 22018\n",
      "Transformed node ID: 324722, total size: 10405, metadata size: 328, main text size: 10077\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Configure llama_index, including setting up embedding\n",
    "# This works for llama_index Version: 0.11.14\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# Configure embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./storage/chroma_cr_jira\")\n",
    "collection = db.get_or_create_collection(\"cr_jira_db\")\n",
    "\n",
    "# Indexing documents with chunking\n",
    "def split_document_into_chunks(document, chunk_size=CHUNK_SIZE):\n",
    "    \"\"\"\n",
    "    Splits a document into chunks with the specified size.\n",
    "    \"\"\"\n",
    "    text = document.text\n",
    "    chunks = []\n",
    "    for idx, i in enumerate(range(0, len(text), chunk_size)):\n",
    "        chunk_text = text[i:i + chunk_size]\n",
    "        chunk_document = Document(\n",
    "            text=chunk_text,\n",
    "            doc_id=document.doc_id,\n",
    "            extra_info={\n",
    "                \"chunk_idx\": idx,  # Track chunk index\n",
    "                **document.extra_info  # Carry over additional metadata\n",
    "            }\n",
    "        )\n",
    "        chunks.append(chunk_document)\n",
    "    return chunks\n",
    "\n",
    "def index_documents_with_chunking(documents, chunk_size=CHUNK_SIZE):\n",
    "    \"\"\"\n",
    "    Index documents by splitting them into smaller chunks.\n",
    "    \"\"\"\n",
    "    chunked_documents = []\n",
    "    for document in documents:\n",
    "        chunks = split_document_into_chunks(document, chunk_size)\n",
    "        chunked_documents.extend(chunks)\n",
    "    \n",
    "    vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    index = VectorStoreIndex.from_documents(chunked_documents, storage_context=storage_context)\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Now run the indexing process\n",
    "reader.set_verbose(False)\n",
    "documents = reader.load_data(query='Project = \"Cybereason Defenders\" AND status = Closed ORDER BY created DESC', start_at=0, max_results=500)\n",
    "index = index_documents_with_chunking(documents, chunk_size=CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Context Sent to ChatGPT:\n",
      " Title: 00342462 | can't increase policies limit\n",
      "URL: https://cybereason.atlassian.net/browse/DFND-69594\n",
      "\n",
      "00342462 | can't increase policies limit \n",
      " Hello,\n",
      "----\n",
      "I can’t increase the policies limit…\n",
      "Related KB:\n",
      "[https://nest.cybereason.com/knowledgebase/2584194|https://nest.cybereason.com/knowledgebase/2584194]\n",
      "Consul:\n",
      "[http://cr-consul.prod.cybereason.net:8500/ui/us-east-1/kv/ms-suits/sensor-management-suite/stacks/bnkbqmsr-stack/config/sm-management/service.policy.max-allowed/edit|http://cr-consul.prod.cybereason.net:8500/ui/us-east-1/kv/ms-suits/sensor-management-suite/stacks/bnkbqmsr-stack/config/sm-management/service.policy.max-allowed/edit]\n",
      "Java exception seen in catalina during the process of creating test policy called “test1234”.\n",
      "Sharing output of catalina during the policy creation process: “creating_policy_test1234_catalina.log”\n",
      "{noformat}java.util.concurrent.ExecutionException: java.lang.RuntimeException: io.grpc.StatusRuntimeException: UNKNOWN\n",
      "        at com.google.common.ut\n"
     ]
    }
   ],
   "source": [
    "# Part 5 - search context from vector database\n",
    "\n",
    "search_text = \"Any issue related to not able to increase policy limit\"\n",
    "embedding = Settings.embed_model.get_text_embedding(search_text)\n",
    "results = collection.query(\n",
    "    query_embeddings=[embedding],\n",
    "    n_results=1  # Limit to only the top result\n",
    ")\n",
    "\n",
    "# Function to filter out duplicate lines and limit context size\n",
    "def filter_context(context_str, max_size=1000):\n",
    "    # Remove duplicate lines by converting to a set and back to a list\n",
    "    unique_lines = list(dict.fromkeys(context_str.split(\"\\n\")))\n",
    "    filtered_context = \"\\n\".join(unique_lines)\n",
    "\n",
    "    # Limit context to max_size characters\n",
    "    if len(filtered_context) > max_size:\n",
    "        filtered_context = filtered_context[:max_size]\n",
    "\n",
    "    return filtered_context\n",
    "\n",
    "# Extract context and metadata from the first result\n",
    "document = results['documents'][0]  # Extract the document text\n",
    "metadatas = results['metadatas'][0]  # Extract the metadata list\n",
    "context_str = \"\\n\".join(document)\n",
    "\n",
    "# Get metadata (url and title)\n",
    "url = metadatas[0].get('url', 'No URL available')\n",
    "title = metadatas[0].get('title', 'No Title available')\n",
    "\n",
    "# Add url and title to the context string\n",
    "context_str = f\"Title: {title}\\nURL: {url}\\n\\n{context_str}\"\n",
    "\n",
    "# Filter the context string to remove duplicates and limit size\n",
    "context_str = filter_context(context_str, max_size=1000)\n",
    "\n",
    "# Print the metadata and context\n",
    "print(\"\\nFinal Context Sent to ChatGPT:\\n\", context_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of the prompt sent to ChatGPT: 1613\n",
      "Prompt sent to ChatGPT:\n",
      "\n",
      "You have very comprehensive knowledge and deep insights into cybersecurity, network, and operating system domains.\n",
      "Always answer the query using only the provided context information, and not prior knowledge.\n",
      "Some rules to follow: \n",
      "1. Always provide the Jira ticket URL when answering with information from any Jira ticket.\n",
      "2. Using both the context information and your own knowledge.\n",
      "3. Always make sure to include the URL of the Jira ticket provided in the context.\n",
      "Context information is below. \n",
      "-----------------\n",
      "Title: 00342462 | can't increase policies limit\n",
      "URL: https://cybereason.atlassian.net/browse/DFND-69594\n",
      "\n",
      "00342462 | can't increase policies limit \n",
      " Hello,\n",
      "----\n",
      "I can’t increase the policies limit…\n",
      "Related KB:\n",
      "[https://nest.cybereason.com/knowledgebase/2584194|https://nest.cybereason.com/knowledgebase/2584194]\n",
      "Consul:\n",
      "[http://cr-consul.prod.cybereason.net:8500/ui/us-east-1/kv/ms-suits/sensor-management-suite/stacks/bnkbqmsr-stack/config/sm-management/service.policy.max-allowed/edit|http://cr-consul.prod.cybereason.net:8500/ui/us-east-1/kv/ms-suits/sensor-management-suite/stacks/bnkbqmsr-stack/config/sm-management/service.policy.max-allowed/edit]\n",
      "Java exception seen in catalina during the process of creating test policy called “test1234”.\n",
      "Sharing output of catalina during the policy creation process: “creating_policy_test1234_catalina.log”\n",
      "{noformat}java.util.concurrent.ExecutionException: java.lang.RuntimeException: io.grpc.StatusRuntimeException: UNKNOWN\n",
      "        at com.google.common.ut\n",
      "-----------------\n",
      "Answer the question: Any issue related to not able to increase policy limit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 6 - Query with context\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# Modify the prompt template to emphasize inclusion of the URL in the response\n",
    "text_qa_template_str = (\n",
    "    \"You have very comprehensive knowledge and deep insights into cybersecurity, network, and operating system domains.\\n\"\n",
    "    \"Always answer the query using only the provided context information, and not prior knowledge.\\n\"\n",
    "    \"Some rules to follow: \\n\"\n",
    "    \"1. Always provide the Jira ticket URL when answering with information from any Jira ticket.\\n\"\n",
    "    \"2. Using both the context information and your own knowledge.\\n\"\n",
    "    \"3. Always make sure to include the URL of the Jira ticket provided in the context.\\n\"\n",
    "    \"Context information is below. \\n\"\n",
    "    \"-----------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"-----------------\\n\"\n",
    "    \"Answer the question: {query_str}\\n\"\n",
    ")\n",
    "\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "\n",
    "# Prepare the query and context\n",
    "query_str = search_text\n",
    "\n",
    "# Render the prompt template with the context and query\n",
    "rendered_prompt = text_qa_template.format(context_str=context_str, query_str=query_str)\n",
    "\n",
    "# Calculate and print the length of the text sent to ChatGPT\n",
    "print(\"\\nLength of the prompt sent to ChatGPT:\", len(rendered_prompt))\n",
    "\n",
    "# Log the prompt that will be sent to ChatGPT\n",
    "print(\"Prompt sent to ChatGPT:\\n\")\n",
    "print(rendered_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response from ChatGPT:\n",
      "\n",
      "Based on the provided context information from Jira ticket 00342462, it seems that the issue reported is related to not being able to increase the policies limit. The user mentioned that they can't increase the policies limit and provided a link to a related Knowledge Base article and a Consul link for configuration.\n",
      "\n",
      "To troubleshoot this issue further, the user also shared a Java exception seen in catalina during the process of creating a test policy called \"test1234\". The output of catalina during the policy creation process is shared in the file \"creating_policy_test1234_catalina.log\".\n",
      "\n",
      "To address this issue, it would be necessary to review the Java exception in the catalina log file to understand the specific error message and stack trace that occurred during the policy creation process. Additionally, checking the configuration in Consul related to the policies limit could also provide insights into why the limit cannot be increased.\n",
      "\n",
      "For a more detailed analysis and resolution of this issue, it is recommended to review the Java exception details in the log file and investigate the Consul configuration settings provided in the link. This information can help in identifying the root cause of the issue and implementing the necessary changes to increase the policies limit successfully.\n",
      "\n",
      "For more information and updates on this specific issue, you can refer to the Jira ticket at: [https://cybereason.atlassian.net/browse/DFND-69594](https://cybereason.atlassian.net/browse/DFND-69594)\n"
     ]
    }
   ],
   "source": [
    "# Send the prompt to the query engine\n",
    "response = index.as_query_engine(\n",
    "    text_qa_template=text_qa_template\n",
    ").query(query_str)\n",
    "\n",
    "# Optionally log the response\n",
    "print(\"\\nResponse from ChatGPT:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of the prompt sent to ChatGPT: 1549\n",
      "Prompt sent to ChatGPT:\n",
      "\n",
      "You have very comprehensive knowledge and deep insights into cybersecurity, network and operating system domain.\n",
      "Always answer the query only using the provided context information, and not prior knowledge.\n",
      "Some rules to follow: \n",
      "1. Using both the context information and also using your own knowledge.\n",
      "2. Give link of the Jira ticket if you are answering with information from any Jira ticket.\n",
      "Context information is below. \n",
      "-----------------\n",
      "try, please make sure they also send the *installation logs*, as in last time\n",
      "\n",
      "Thanks\n",
      "Hello [~accountid:61f62b8dacd4cb0069befbe1], thanks for uploading the files. Per reviewing the procmon file, I still believe Morphisec may be the cause to the issue.\n",
      "\n",
      "ProtectorService.exe is Morphisec sensor/agent, we can see it running in parallel to our installer and also doing actions related to the installer (on the installer)\n",
      "\n",
      "The difference between the existing working machines (morphisec + cybereason working) and current non-able to install can relate to configuration, versions, time of install or what ever cause that may make Morphisec block Cybereason…\n",
      "\n",
      "Please request the customer to try and remove/disable Morphisec *on an “infected” endpoint*, prior to running the installer and only if that fails let’s schedule a session.\n",
      "\n",
      "No need for a new procmon, but please ask him to make sure ProtectorService64.exe is not working during the installation, or else it’s a redundant test.\n",
      "\n",
      "[~accountid:55705\n",
      "-----------------\n",
      "Answer the question: Please suggest link of Jira ticket which your answer is based on\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare the query and context\n",
    "query_str = \"Please suggest link of Jira ticket which your answer is based on\"\n",
    "\n",
    "# Render the prompt template with the context and query\n",
    "rendered_prompt = text_qa_template.format(context_str=context_str, query_str=query_str)\n",
    "\n",
    "# Calculate and print the length of the text sent to ChatGPT\n",
    "print(\"\\nLength of the prompt sent to ChatGPT:\", len(rendered_prompt))\n",
    "\n",
    "# Log the prompt that will be sent to ChatGPT\n",
    "print(\"Prompt sent to ChatGPT:\\n\")\n",
    "print(rendered_prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_new_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Make sure to use the correct ChatCompletion method\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest message\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Projects/18_jirarag/myenv/lib/python3.12/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set the API key directly\n",
    "openai.api_key = \"your_new_api_key\"\n",
    "\n",
    "# Make sure to use the correct ChatCompletion method\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"Test message\"}]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
